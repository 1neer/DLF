이번주차는 옵티마이저를 구현하고, 데이터 전처리를 dezero에서 수행하였다.

먼저 매개변수를 갱신 하는데에는 경사하강법을 사용하며, 다양한 최적화 기법이 제안되었다.
이를위해 옵티마이저 클래스를 만들었다.
옵티마이저 클래스는 매개변수 갱신을 위한 기반 클래스이며, 구체적인 최적화 기법은 Optimizer 클래스를 상속한 자식 클래스에서 구현한다.
초기화 메서드 target과 hooks 라는 두 개의 인스턴스 변수를 초기화 하며, setup 메소드는 매개변수를 갖는 클래스를 인스턴스 변수인 target으로 설정한다.
또한 update 메서드는 모든 매개변수를 갱신하고, 구체적인 매개변수 갱신은 update_one 메서드에서 수행, 자식 클래스에서 재정의한다.
그 후 경사하강법으로 매개변수를 갱신하는 SGD클래스를 구현한다.

이러한 SGD이외에도 최적화 기법이 존재하는데 Momentum, AdaGrad, AdaDelta, Adam등등이 있다.
이것들을 옵티마이저 클래스를 이용해 필요에 따라 손쉽게 전환할 수 있다.

그 다음으로 다중 클래스 분류에 대해 배웠다.
다중 클래스 분류란 여러 클래스로 분류하는 문제이며, 분류 대상이 여러 가지 클래스 중 어디에 속하는지 추정한다.
이를 위해서 먼저 슬라이스 조작 함수를 만든다.
먼저 Variable의 다차원 배열 중에서 일부를 슬라이스하여 뽑아줌, 그 후 (2, 3) 형상의 x에서 1번째 행의 원소를 추출한다. 이 함수는 DeZero 함수로 구현했기 때문에 역전파도 제대로 수행 할 수 있다.
슬라이스란 다차원 배열의 일부를 추출하는 작업이다. ( 파이썬 슬라이스 조작 예 : x[1:4] )

다음으로는 소프트맥스 함수에 대해 배웠다.
이 소프트 맥스 함수는 출력이 단순한 수치인데, 이 수치를 확률로 변환시킨다.

그 다음으로는 교차 엔트로피 오차가 있다.
이는 다중 클래스 분류에 적합한 손실 함수로, 정답 데이터의 원소는 정답에 해당하는 클래스면 1로, 그렇지 않으면 0으로 기록한다.
이러한 표현 방식을 원핫 벡터 (onehot vector)라 한다.

다음으로는 이때까지 구현한 코드로 다중 클래스 분류를 진행하였다.
스파이럴 데이터셋 이라는 작은 데이터셋을 사용하여 다중 클래스 분류를 실제로 수행해보았다.

다음으로는 데이터셋 클래스를 구현한 뒤 전처리를 진행하였다.
Dataset 클래스는 기반 클래스로서의 역할을 하고, 실제로 사용하는 데이터셋은 이를 상속하여 구현한다.
prepare 메서드가 데이터 준지 작업을 하도록 구현했고, __getitem__ 메서드는 단순히 지정된 인덱스에 위치하는 데이터를 꺼낸다.
__len__ 메서드는 데이터셋의 길이를 알려준다.

그리고 큰 데이터셋을 처리할 경우 BigData 클래스를 초기화할 떄는 데이터를 읽지 않고, 데이터에 접근하는 __getitem__(index)가 불리는 시점에 데이터를 읽는다.
그 후 신경망을 학습시킬 때는 데이터 셋 중 일부를 미니배치로 꺼내고, 인덱스를 지정하여 batch에 여러 데이터가 리스트로 저장하고, ndarray 인스턴스로 변환한다.

그 후 어텐션에 대해서 배웠다.
기존 seq2seq의 문제점은 고정 길이 벡터는 입력 문장의 길이에 관계없이 항상 같은 길이의 벡터로 변환하고, 아무리 긴 문장이 입력되더라도 항상 똑같은 길이의 벡터에 밀어 넣었다.

이를 개선하기 위해 ▪LSTM 계층의 마지막 은닉 상태만을 Decoder에 전달하고, Encoder의 출력 길이는 입력 문장에 따라 바꿔주도록 한다. 또한 은닉 상태 벡터를 모두 이용하면 입력된 단어와 같은 수의 벡터를 얻는다.
또한 ‘도착어 단어’와 대응 관계에 있는 ‘출발어 단어’의 정보를 골라 내는 것, 필요한 정보에만 주목하여 그 정보로부터 시계열 변환을 수행하는 것이 필요했는데 이것이 바로 어텐션의 키 아이디어다.
그를 위해 단어에 대한 가중치를 구하고, 가중합 계산을 통해 맥락 벡터를 구한다.
