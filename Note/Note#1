먼저 1주차에서는 딥러닝의 간단한 기초부터 미분자동계산까지 배워보았다.
먼저 머신러닝에서의 훈련이란 훈련 데이터로부터 가중치 매개변수의 최적값을 자동으로 획득 하는 것을 의미한다.
이것에 대해서는 증거가 발생했을 때 가설이 일어날 확률인 베이즈 정리,
손실함수이자, 촤적의 매개변수 값을 탐색하는 지표인 평균 제곱 오차,
미분과 선형대수 등등 수학적요소가 아주 많이 포함이 되어있다.

그 다음으로는 역전파 이론을 배웠는데, 역전파란 하나의 학습 데이터에 대해 그레디언트를 계산하는 방법이며,
미분을 효율적으로 계산할 수 있고, 결과값의 오차도 적다.
이는 연쇄법칙에 따라서 만들어졌는데, 연쇄법칙이란 여러함수를 사슬처럼 연결하여 사용하는것으로, 합성함수의 미분은 구성함수 각각을 미분후 곱한것과 같다.

이를 토대로 역전파의 원리를 설명할 수 있다.

2주차에서는 딥러닝의 역전파와 이를 자동화하는 법을 배웠다.
먼저 역전파를 구현하기 위해 data와 미분값을 저장하는 Variable 클래스를 만들었다.
그런 후 순전파를 계산하는 forward 함수와 역전파를 계산하는 backward함수를 구현하였고, 
이를 통해 순전파는 x -> A -> a -> B -> b -> C -> y 처럼 정방향으로 흐르게 설계한다면, 
역전파는 이와 반대로 y -> C -> b -> B -> a -> A -> x 순으로 진행이 되게 코드를 작성한다.

하지만 이를 역전파를 실행할때마다 수동으로 해줄수는 없으니, 이를 자동화하는과정이 필요하였다.
그렇기 때문에 순전파를 한번만 수행하면 어떤 계산이여도 역전파가 자동으로 이루어 지는 구조를 만들어야하였다.
이를 구현하기 위해서는 변수와 함수의 관계를 이해하여야 하는데, 함수입장에서 변수는 입력과 출력이고, 변수에게있어 함수는 창조자의 관계이다.
이를 코드로 구현하기 위해 Variable 클래스에 creator 인스턴스 변수와 set_creator() 메서드를 만들었다.
또한 계산 그래프를 거꾸로 올라가기 위해 assert문으로 조건을 충족하는지 먼저 확인할 필요가 있었다.

그 후 역전파의 진행순서는 함수를 가져오고, 그다음은 함수의 입력을 가져온 뒤, backward 메서드를 호출하는 순으로 진행이 되므로 이를 코드로 구현한다.
그다음에는 Variable 클래스에 backward 메서드를 추가하여 반복작업을 자동화 시키는 작업을 한다.

하지만 현재의 방식은 재귀를 사용한 구현이기때문에 효율이 떨어진다. 때문에 재귀가 아닌 반복문을 이용하면 중간결과를 메모리에 유지하면서 처리하기 때문에 효율이 더욱 좋아진다.
또한 ndarray 인스턴스만 취급하게 만들어 ndarray 이외의 데이터를 넣을 경우 즉시 오류가 발생하도록 예외처리를 진행하여 output이 항상 ndarray가 될 수 있도록 보장을 해줄수도 있다.

여기까지 직접 역전파를 구현해 보았는데 그전에는 막연히 역전파는 가중치를 업데이트 시키는 과정이라고만 생각했는데, 직접 구현하고 눈으로 살펴보니 좀 더 그과정을 정확하게 알 수 있었던것 같다.

